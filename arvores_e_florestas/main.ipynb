{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Atividade 3 - Árvores de decisão e Floresta Aletatótia\n",
    "\n",
    "**Disciplina:** Inteligência Artificial\n",
    "\n",
    "**Professor:** Anderson Cavalcanti\n",
    "\n",
    "**Discentes:** **Maria Clara da Silva Ferreria** & **Yann Keven Jordão Leão**"
   ],
   "metadata": {
    "id": "X2jpKwFlQv6f"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parte 1: Aplicando a Floresta ao Dataset Iris"
   ],
   "metadata": {
    "id": "S978POkqSEyK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparando o dataset"
   ],
   "metadata": {
    "id": "r0e21rDWU83G"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sGCqF981QWQY"
   },
   "source": [
    "# Importantos as dependências\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer, load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Carregando o dataset\n",
    "iris = load_iris()"
   ],
   "metadata": {
    "id": "ei-0yguWTAVv"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Definindo parâmetros(X) e Alvo(y)\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = pd.Series(iris.target).map({0: 'Setosa', 1: 'Versicolor', 2: 'Virginica'})"
   ],
   "metadata": {
    "id": "VTYDor6rT0cX"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Separando em dados de teste e treino\n",
    "X_test, X_train, y_test, y_train = train_test_split(X, y, test_size=0.3, random_state=64)"
   ],
   "metadata": {
    "id": "8yvG0GTMUfYf"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Treinando o modelo de Árvore de Decisão"
   ],
   "metadata": {
    "id": "zRXFhXmqVBY-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Criação\n",
    "arvore = DecisionTreeClassifier(random_state=64)\n",
    "\n",
    "# Teste\n",
    "arvore.fit(X_train, y_train)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R8vg68BIU3ZV",
    "outputId": "20fe9efd-6b50-480d-9ff2-7eaad4a1ac2b"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Fazendo previsão com o 'test'\n",
    "pred_arvore = arvore.predict(X_test)"
   ],
   "metadata": {
    "id": "xdffmoRxVZj8"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Avaliando a acurácia\n",
    "acuracy_arvore = accuracy_score(y_test, pred_arvore)\n",
    "acuracy_arvore"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AD_jfSoWVhTr",
    "outputId": "38cc0abb-02c2-451c-ea68-ba6979b6b283"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Treinando o modelo de Floresta Aleatória"
   ],
   "metadata": {
    "id": "9iOyv_KDWE9e"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Criação\n",
    "floresta = RandomForestClassifier(n_estimators=100, random_state=64)\n",
    "\n",
    "# Teste\n",
    "floresta.fit(X_train, y_train)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cvCumSVfV02j",
    "outputId": "c3f9e384-7370-474e-880b-4b7361fa1bf5"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Fazendo previsão com o 'test'\n",
    "pred_floresta = floresta.predict(X_test)"
   ],
   "metadata": {
    "id": "aqHnC2DRWl39"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Avaliando a acurácia\n",
    "acuracy_floresta = accuracy_score(y_test, pred_floresta)\n",
    "acuracy_floresta"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H3L19-78WufR",
    "outputId": "c6a79b68-fbb3-4c00-9e75-731f736ca04c"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "fig.suptitle('Comparação de Desempenho no Conjunto de TESTE', fontsize=16)\n",
    "\n",
    "# Matriz para a Árvore de Decisão\n",
    "cm_arvore = confusion_matrix(y_test, pred_arvore)\n",
    "sns.heatmap(cm_arvore, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=floresta.classes_, yticklabels=floresta.classes_)\n",
    "axes[0].set_title('Única Árvore de Decisão')\n",
    "axes[0].set_xlabel('Previsão')\n",
    "axes[0].set_ylabel('Real')\n",
    "\n",
    "# Matriz para a Floresta Aleatória\n",
    "cm_floresta = confusion_matrix(y_test, pred_floresta)\n",
    "sns.heatmap(cm_floresta, annot=True, fmt='d', cmap='Greens', ax=axes[1],\n",
    "            xticklabels=floresta.classes_, yticklabels=floresta.classes_)\n",
    "axes[1].set_title('Floresta Aleatória')\n",
    "axes[1].set_xlabel('Previsão')\n",
    "axes[1].set_ylabel('Real')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZ6m1oSKW8wj",
    "outputId": "fb249ca5-bf14-4bbb-c77b-b1821f22d32e"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analisando a importânica das Features"
   ],
   "metadata": {
    "id": "Xu-6IQYAYmVi"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Uttilizando a floresta aleatória para a análise\n",
    "importancias = pd.Series(data=floresta.feature_importances_, index=X.columns)"
   ],
   "metadata": {
    "id": "tacVm95eXogo"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Ordenando e pegando as 10 mais importantes\n",
    "importancias_sorted = importancias.sort_values(ascending=False).head(10)"
   ],
   "metadata": {
    "id": "4Kbprhr_YxJl"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Criando o gráfico\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(\n",
    "    x=importancias_sorted,\n",
    "    y=importancias_sorted.index,\n",
    "    hue=importancias_sorted.index,\n",
    "    palette='viridis',\n",
    "    legend=False\n",
    "    )\n",
    "plt.title('Top 10 Features Mais Importantes', fontsize=16)\n",
    "plt.xlabel('Nível de Importância')\n",
    "plt.ylabel('Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7g2Hx-g7Y9M-",
    "outputId": "6fb0adf5-0913-4a47-a9c8-eece06a77fc9"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perguntas - Parte 1\n",
    "\n",
    "**1. A única Árvore de Decisão sofreu overfitting neste novo dataset?**\n",
    "\n",
    "Sim. O modelo de Árvore de Decisão apresentou overfitting, pois não foi definida uma profundidade máxima durante o treinamento. Isso faz com que a árvore cresça até o limite, ajustando-se completamente aos dados de treino — inclusive aos ruídos — o que leva a uma generalização ruim.\n",
    "Essa situação fica evidente ao observar que o modelo obteve 100% de acurácia no conjunto de treino, enquanto a acurácia no conjunto de teste foi inferior, indicando que ele memorizou o conjunto de treino ao invés de aprender padrões gerais.\n",
    "\n",
    "**2. A Floresta Aleatória teve um desempenho superior ao da única árvore no conjunto de teste?**\n",
    "\n",
    "Sim. A Floresta Aleatória apresentou um desempenho melhor no conjunto de teste.\n",
    "A acurácia obtida pela Floresta Aleatória foi 0.9333, enquanto a da Árvore de Decisão única foi 0.9143.\n",
    "Isso representa uma diferença de aproximadamente 2,09% de desempenho superior da Floresta Aleatória.\n",
    "Esse resultado é esperado, pois o método de ensemble combina diversas árvores, reduzindo a variância e, consequentemente, o risco de overfitting.\n",
    "\n",
    "**3. De acordo com o gráfico gerado, qual foi a característica mais importante que o modelo usou para classificar as espécies de flores?**\n",
    "\n",
    "De acordo com o gráfico de importância das variáveis, as características mais relevantes para a classificação das espécies de flores foram:\n",
    "\n",
    "Comprimento da pétala (petal length) – a variável mais importante para a decisão do modelo;\n",
    "\n",
    "Largura da pétala (petal width) – a segunda mais expressiva.\n",
    "\n",
    "Já as medidas relacionadas à sépala (comprimento e largura da sépala) tiveram importância significativamente menor, indicando que as dimensões das pétalas são os principais atributos utilizados pelo modelo para distinguir as espécies de flores."
   ],
   "metadata": {
    "id": "Ot2Aes1yaZqd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parte 2: Ajustando os Hiperparâmetros da Floresta"
   ],
   "metadata": {
    "id": "_4SeyTwYahPf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparando o dataset"
   ],
   "metadata": {
    "id": "6ulVGmzbc5F3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Carregando dataset\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "y = pd.Series(cancer.target).map({0: 'Maligno', 1: 'Benigno'})\n",
    "\n",
    "# Dividindo em teste e treino\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=64)"
   ],
   "metadata": {
    "id": "JiPNuBpoaYIP"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tarefa 2.1: O Efeito do Número de Árvores (n_estimators)"
   ],
   "metadata": {
    "id": "tV3OSKVBd2SV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Lista de valores para n_estimators\n",
    "n_estimators_list = [1, 10, 20, 50, 100, 200]\n",
    "results_estimator = []\n",
    "\n",
    "# Loop para testar diferentes quantidades de árvores\n",
    "for n in n_estimators_list:\n",
    "    model = RandomForestClassifier(n_estimators=n, random_state=64)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results_estimator.append({'n_estimators': n, 'acuracia': acc})\n",
    "\n",
    "results_df = pd.DataFrame(results_estimator)"
   ],
   "metadata": {
    "id": "NYLORKUmdAXR"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Visualizando os resultados\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(data=results_df, x='n_estimators', y='acuracia', marker='o', color='tab:blue')\n",
    "plt.title('Efeito do Número de Árvores na Acurácia da Random Forest', fontsize=13)\n",
    "plt.xlabel('Número de Árvores (n_estimators)')\n",
    "plt.ylabel('Acurácia no Conjunto de Teste')\n",
    "plt.xticks(n_estimators_list)\n",
    "plt.ylim(0.9, 1.0)\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 498
    },
    "id": "re5DWnnkeSR8",
    "outputId": "ec12a6f2-cb80-4c83-fca1-20434d14edfe"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**4. O que acontece com a acurácia à medida que aumentamos o número de árvores na\n",
    "floresta? A performance melhora indefinidamente ou chega a um ponto em que o ganho é\n",
    "muito pequeno?**\n",
    "\n",
    "Ao aumentar o número de árvores na Floresta Aleatória, observamos que a acurácia melhora significativamente entre 1 e 10 árvores, passando de aproximadamente 0.918 para 0.959 — um salto considerável que demonstra o efeito positivo do ensemble (a combinação de múltiplas árvores reduz a variância e melhora a generalização do modelo).\n",
    "\n",
    "A partir de 10 árvores, entretanto, o desempenho se estabiliza, com valores praticamente idênticos de acurácia para 10, 20, 50 e 200 árvores (em torno de 0.959).\n",
    "Isso indica que, após certo ponto, adicionar mais árvores traz ganhos marginais ou nulos, pois o modelo já atingiu um nível ótimo de generalização.\n",
    "\n",
    "Curiosamente, há uma pequena queda em 100 árvores (para 0.953), que provavelmente se deve a variações aleatórias no processo de amostragem dos dados."
   ],
   "metadata": {
    "id": "B-CgBXSLgIqm"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tarefa 2.2: O Efeito da Profundidade das Árvores (max_depth)"
   ],
   "metadata": {
    "id": "WA_ZIkWOgnpb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Lista de valores para max_depth\n",
    "max_depth_list = [1, 2, 3, 5, 10, None]\n",
    "results = []\n",
    "\n",
    "# Loop para testar diferentes profundidades\n",
    "for n in max_depth_list:\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=n, random_state=64)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results.append({'max_depth': n, 'acuracia': acc})\n",
    "\n",
    "results_depth_df = pd.DataFrame(results)"
   ],
   "metadata": {
    "id": "fAbn_oN5efE9"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Tirando o 'None' para plotar o gráfico\n",
    "results_depth_plot = results_depth_df.dropna(subset=['max_depth'])\n",
    "\n",
    "# Visualizando os resultados\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(data=results_depth_plot, x='max_depth', y='acuracia', marker='o', color='tab:orange')\n",
    "plt.title('Efeito da Profundidade Máxima na Acurácia da Random Forest', fontsize=13)\n",
    "plt.xlabel('Profundidade da árvore (max_depth)')\n",
    "plt.ylabel('Acurácia no Conjunto de Teste')\n",
    "plt.ylim(0.9, 1.0)\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "93tJm7oqhXgk",
    "outputId": "a5f910ea-35d0-45e9-a623-89f01237f4c4"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**5. Como o parâmetro max_depth afeta o overfitting? Descreva o que aconteceu com a\n",
    "acurácia de treino e a de teste à medida que a profundidade das árvores aumentou.**\n",
    "\n",
    "Ao analisar o efeito da profundidade máxima (max_depth) das árvores na Floresta Aleatória, observamos que a acurácia aumenta gradualmente até certo ponto e, a partir daí, se estabiliza.\n",
    "\n",
    "Nos primeiros valores, há um ganho visível:\n",
    "\n",
    "- Com profundidade 1, a acurácia é de 0.9239,\n",
    "- Com profundidade 2 e 3, ela sobe para 0.9415,\n",
    "- E atinge 0.9532 a partir da profundidade 5.\n",
    "\n",
    "A partir desse ponto, mesmo ampliando a profundidade para 10 ou deixando sem limite (None), o desempenho permanece praticamente o mesmo, indicando que o modelo já capturou toda a complexidade relevante dos dados.\n",
    "\n",
    "Esse comportamento mostra que, após uma profundidade intermediária, o modelo não ganha mais capacidade de generalização — ele apenas se torna mais complexo, o que pode até aumentar o risco de overfitting em outros conjuntos de dados."
   ],
   "metadata": {
    "id": "Ea_BLiOvj8YL"
   }
  }
 ]
}
